{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"NilePlateID","text":"<p>Egyptian License Plate Recognition with AI</p> <p>NilePlateID is an end-to-end AI pipeline for detecting Egyptian license plates, recognizing Arabic text, and re-identifying vehicles across cameras.</p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>\ud83d\udd0d YOLO Detection - Car and license plate detection with YOLOv11</li> <li>\ud83d\udd24 Arabic OCR - Custom YOLO OCR trained on Egyptian plates</li> <li>\ud83d\ude97 Vehicle ReID - Re-identify cars across cameras using deep learning</li> <li>\ud83d\udda5\ufe0f Streamlit App - Interactive web demo with premium UI</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"Documentation Description Getting Started Installation and setup Architecture System design overview Classical CV Traditional CV approaches YOLO Detection Deep learning detection Vehicle ReID Re-identification system API Reference CLI commands"},{"location":"#demo","title":"Demo","text":"<p>Run the Streamlit app:</p> <pre><code>uv run streamlit run app.py\n</code></pre> <p>Open <code>http://localhost:8501</code> in your browser.</p>"},{"location":"api/","title":"API Reference","text":"<p>Command-line interface for batch processing.</p>"},{"location":"api/#installation","title":"Installation","text":"<pre><code>pip install uv\nuv sync\n</code></pre>"},{"location":"api/#commands","title":"Commands","text":""},{"location":"api/#run-full-pipeline","title":"Run Full Pipeline","text":"<p>Process images through detection + OCR:</p> <pre><code>uv run python -m src.cli run \\\n    --weights models/best.pt \\\n    --input data/incoming \\\n    --gallery data/gallery \\\n    --plates data/plates \\\n    --index data/meta/index.csv \\\n    --conf 0.25 \\\n    --iou 0.45 \\\n    --pad 0.05 \\\n    --ocr_min_conf 0.3\n</code></pre> <p>Parameters:</p> Flag Default Description <code>--weights</code> <code>models/best.pt</code> YOLO detection weights <code>--input</code> required Input images directory <code>--gallery</code> <code>data/gallery</code> Output car crops <code>--plates</code> <code>data/plates</code> Output plate crops <code>--index</code> <code>data/meta/index.csv</code> Output index file <code>--conf</code> 0.25 Detection confidence <code>--iou</code> 0.45 NMS IoU threshold <code>--pad</code> 0.05 Crop padding fraction <code>--ocr_min_conf</code> 0.3 Min OCR confidence"},{"location":"api/#detect-only","title":"Detect Only","text":"<p>Run detection without OCR:</p> <pre><code>uv run python -m src.cli detect \\\n    --weights models/best.pt \\\n    --input data/incoming \\\n    --out data/meta/detections.json\n</code></pre>"},{"location":"api/#video-frames","title":"Video Frames","text":"<p>Extract frames from video:</p> <pre><code>uv run python -m src.cli video-frames \\\n    --video path/to/video.mp4 \\\n    --out_dir data/incoming_video/video \\\n    --fps 2\n</code></pre> <p>With OCR filtering (keep only readable plates):</p> <pre><code>uv run python -m src.cli video-frames \\\n    --video path/to/video.mp4 \\\n    --out_dir data/incoming_video/video \\\n    --fps 2 \\\n    --require_ocr \\\n    --weights models/best.pt \\\n    --ocr_min_conf 0.05\n</code></pre>"},{"location":"api/#build-reid-index","title":"Build ReID Index","text":"<p>Create gallery embeddings:</p> <pre><code>uv run python -m src.cli reid-index \\\n    --gallery_dir data/gallery \\\n    --reid_opts models/reid/opts.yaml \\\n    --reid_ckpt models/reid/net.pth \\\n    --index_dir data/meta/reid\n</code></pre>"},{"location":"api/#reid-search","title":"ReID Search","text":"<p>Search for a vehicle:</p> <pre><code>uv run python -m src.cli reid-search \\\n    --plate_id ABC123 \\\n    --input_dir data/incoming \\\n    --index_dir data/meta/reid \\\n    --min_score 0.6\n</code></pre> <p>Parameters:</p> Flag Default Description <code>--plate_id</code> required Target plate ID <code>--input_dir</code> <code>data/incoming</code> Query images <code>--index_dir</code> <code>data/meta/reid</code> Gallery index <code>--min_score</code> 0.0 Min cosine similarity <code>--top_k</code> 5 Max matches per image"},{"location":"api/#clean-artifacts","title":"Clean Artifacts","text":"<p>Remove generated files:</p> <pre><code># Dry run (preview)\nuv run python -m src.cli clean --dry_run\n\n# Force clean\nuv run python -m src.cli clean --force\n</code></pre>"},{"location":"api/#download-models","title":"Download Models","text":"<pre><code>uv run python -m src.download_weights\n</code></pre> <p>Options:</p> Flag Description <code>--force</code> Overwrite existing <code>--strict</code> Fail on any error"},{"location":"api/#output-structure","title":"Output Structure","text":"<pre><code>data/\n\u251c\u2500\u2500 gallery/{plate_id}/     # Car crops indexed by plate\n\u251c\u2500\u2500 plates/{plate_id}/      # Plate crops\n\u251c\u2500\u2500 meta/\n\u2502   \u251c\u2500\u2500 index.csv           # Detection index\n\u2502   \u251c\u2500\u2500 detections.json     # Raw detections\n\u2502   \u251c\u2500\u2500 debug/              # Annotated images\n\u2502   \u2514\u2500\u2500 reid/\n\u2502       \u251c\u2500\u2500 index.npz       # Gallery embeddings\n\u2502       \u251c\u2500\u2500 results.csv     # Search results\n\u2502       \u2514\u2500\u2500 annotated/      # Match visualizations\n</code></pre>"},{"location":"architecture/","title":"System Architecture","text":"<p>NilePlateID uses a modular architecture with three main pipelines.</p>"},{"location":"architecture/#overview","title":"Overview","text":"<pre><code>Input Image/Video\n    \u2502\n    \u251c\u2500\u2500\u2500 Classical CV Pipeline \u2500\u2500\u2500\u25ba Morphological Detection \u2500\u2500\u2500\u25ba EasyOCR\n    \u2502\n    \u251c\u2500\u2500\u2500 YOLO Pipeline \u2500\u2500\u2500\u25ba YOLOv11 Detection \u2500\u2500\u2500\u25ba YOLO OCR \u2500\u2500\u2500\u25ba Arabic Text\n    \u2502\n    \u2514\u2500\u2500\u2500 ReID Pipeline \u2500\u2500\u2500\u25ba Car Detection \u2500\u2500\u2500\u25ba Feature Extraction \u2500\u2500\u2500\u25ba Gallery Matching\n</code></pre>"},{"location":"architecture/#components","title":"Components","text":""},{"location":"architecture/#1-detection-module-srcpipeline","title":"1. Detection Module (<code>src/pipeline/</code>)","text":"File Purpose <code>detection.py</code> YOLO wrapper for car/plate detection <code>ocr.py</code> EasyOCR backend <code>yolo_ocr.py</code> Custom YOLO OCR for Arabic <code>enhancement.py</code> Image preprocessing <code>association.py</code> Plate-to-car matching <code>visualize.py</code> Debug visualization"},{"location":"architecture/#2-reid-module-srcreid","title":"2. ReID Module (<code>src/reid/</code>)","text":"File Purpose <code>search.py</code> Gallery embeddings &amp; matching <code>visualize.py</code> ReID debug visualization"},{"location":"architecture/#3-streamlit-app-srcapp_pages","title":"3. Streamlit App (<code>src/app_pages/</code>)","text":"Page Function <code>classical_page.py</code> Traditional CV + EasyOCR <code>pipeline_page.py</code> YOLO detection + OCR <code>training_page.py</code> Model training dashboard <code>reid_page.py</code> Vehicle re-identification <code>future_work_page.py</code> Roadmap &amp; limitations"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#detection-flow","title":"Detection Flow","text":"<pre><code>Image \u2192 YOLO Detection \u2192 [Car, Plate] boxes\n    \u2192 Crop plate region\n    \u2192 YOLO OCR character detection\n    \u2192 Assemble plate text\n    \u2192 Store car crop indexed by plate ID\n</code></pre>"},{"location":"architecture/#reid-flow","title":"ReID Flow","text":"<pre><code>Registration:\n    Image \u2192 Detect car \u2192 OCR plate \u2192 Save to gallery/{plate_id}/\n\nSearch:\n    Query video \u2192 Detect cars \u2192 Extract features\n    \u2192 Compare with gallery embeddings\n    \u2192 Return matches above threshold\n</code></pre>"},{"location":"architecture/#model-architecture","title":"Model Architecture","text":""},{"location":"architecture/#yolo-detection","title":"YOLO Detection","text":"<ul> <li>Backbone: CSPDarknet with C3k2 blocks</li> <li>Neck: PANet for multi-scale feature aggregation</li> <li>Head: Detection heads at 3 scales (P3, P4, P5)</li> </ul>"},{"location":"architecture/#reid-model","title":"ReID Model","text":"<ul> <li>Backbone: ResNet50-IBN (Instance-Batch Normalization)</li> <li>Embedding: 512-dimensional feature vector</li> <li>Loss: Contrastive + Circle Loss</li> </ul>"},{"location":"classical/","title":"Classical Computer Vision","text":"<p>Traditional image processing approaches for license plate detection.</p>"},{"location":"classical/#overview","title":"Overview","text":"<p>The classical pipeline uses color-based segmentation and morphological operations to detect Egyptian blue license plates.</p>"},{"location":"classical/#detection-methods","title":"Detection Methods","text":""},{"location":"classical/#1-morphological-detection-color-based","title":"1. Morphological Detection (Color-based)","text":"<pre><code># Convert to HSV for blue color detection\nhsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n\n# Blue range for Egyptian plates\nlower_blue = np.array([100, 50, 50])\nupper_blue = np.array([130, 255, 255])\n\n# Create mask\nmask = cv2.inRange(hsv, lower_blue, upper_blue)\n\n# Morphological closing to fill gaps\nkernel = cv2.getStructuringElement(cv2.MORPH_RECT, (25, 25))\nclosed = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n\n# Find contours\ncontours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n</code></pre> <p>Processing Steps:</p> <ol> <li>HSV Conversion - Better color separation than RGB</li> <li>Blue Masking - Isolate Egyptian plate color</li> <li>Morphological Closing - Connect nearby regions</li> <li>Contour Detection - Find plate boundaries</li> <li>Aspect Ratio Filtering - Remove non-plate shapes</li> </ol>"},{"location":"classical/#2-canny-edge-detection","title":"2. Canny Edge Detection","text":"<pre><code># Preprocessing\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nfiltered = cv2.bilateralFilter(gray, 11, 17, 17)\n\n# Edge detection\nedged = cv2.Canny(filtered, 30, 200)\n\n# Find contours\ncontours, _ = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\ncontours = sorted(contours, key=cv2.contourArea, reverse=True)[:30]\n\n# Look for rectangles\nfor c in contours:\n    peri = cv2.arcLength(c, True)\n    approx = cv2.approxPolyDP(c, 0.018 * peri, True)\n\n    if len(approx) == 4:  # Rectangle found\n        x, y, w, h = cv2.boundingRect(approx)\n        aspect_ratio = w / float(h)\n\n        # Egyptian plates: aspect ratio 2-4\n        if 2.0 &lt;= aspect_ratio &lt;= 4.0:\n            plate_roi = gray[y:y+h, x:x+w]\n</code></pre> <p>Key Parameters:</p> Parameter Value Purpose Bilateral d 11 Filter diameter Canny low 30 Lower threshold Canny high 200 Upper threshold Approx epsilon 0.018 Polygon approximation"},{"location":"classical/#harris-corner-validation","title":"Harris Corner Validation","text":"<p>To validate detected plates, we use Harris corner detection:</p> <pre><code>harris_dst = cv2.cornerHarris(plate_roi, blockSize=2, ksize=3, k=0.04)\nharris_corners_count = np.sum(harris_dst &gt; 0.01 * harris_dst.max())\n\n# Plates should have many corners (text)\nif harris_corners_count &gt; 20:\n    # Valid plate detected\n</code></pre>"},{"location":"classical/#ocr-with-easyocr","title":"OCR with EasyOCR","text":"<pre><code>import easyocr\n\nreader = easyocr.Reader(['ar', 'en'])\nresult = reader.readtext(plate_image)\n\n# Process results\nfor (bbox, text, confidence) in result:\n    if confidence &gt; 0.3:\n        print(f\"Detected: {text}\")\n</code></pre>"},{"location":"classical/#limitations","title":"Limitations","text":"<ul> <li>Lighting Sensitivity - Color-based methods fail in low light</li> <li>Angle Dependence - Requires near-frontal view</li> <li>Color Variations - Only works for blue Egyptian plates</li> <li>Noise - Complex backgrounds cause false positives</li> </ul>"},{"location":"classical/#when-to-use","title":"When to Use","text":"Method Best For Morphological Clear, well-lit images with blue plates Canny High-contrast images with visible edges YOLO General use, robust to variations"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10-3.12</li> <li>pip or uv package manager</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/MyronTadros/NilePlateID.git\ncd NilePlateID\n</code></pre>"},{"location":"getting-started/#2-install-dependencies","title":"2. Install Dependencies","text":"<p>Using uv (Recommended):</p> <pre><code>pip install uv\nuv venv\nuv sync\n</code></pre> <p>Using pip:</p> <pre><code>python -m venv .venv\nsource .venv/bin/activate  # Linux/Mac\n# or: .venv\\Scripts\\activate  # Windows\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#3-download-models","title":"3. Download Models","text":"<pre><code>uv run python -m src.download_weights\n</code></pre> <p>This downloads:</p> Model Description Size <code>best.pt</code> YOLO car + plate detection ~50MB <code>yolo11m_car_plate_ocr.pt</code> YOLO Arabic OCR ~40MB <code>reid/net.pth</code> ResNet50-IBN ReID ~100MB"},{"location":"getting-started/#4-run-the-app","title":"4. Run the App","text":"<pre><code>uv run streamlit run app.py\n</code></pre> <p>Open <code>http://localhost:8501</code> in your browser.</p>"},{"location":"getting-started/#project-structure","title":"Project Structure","text":"<pre><code>NilePlateID/\n\u251c\u2500\u2500 app.py                      # Streamlit entry point\n\u251c\u2500\u2500 .streamlit/config.toml      # Theme configuration\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 app_pages/              # Streamlit pages\n\u2502   \u251c\u2500\u2500 pipeline/               # Detection &amp; OCR logic\n\u2502   \u251c\u2500\u2500 reid/                   # ReID system\n\u2502   \u2514\u2500\u2500 cli.py                  # CLI entrypoint\n\u251c\u2500\u2500 models/                     # Model weights\n\u251c\u2500\u2500 data/                       # Generated outputs\n\u2514\u2500\u2500 docs/                       # Documentation\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture Overview</li> <li>Classical CV Methods</li> <li>YOLO Detection</li> <li>Vehicle ReID</li> </ul>"},{"location":"reid/","title":"Vehicle Re-Identification (ReID)","text":"<p>Re-identify vehicles across cameras using deep learning embeddings.</p>"},{"location":"reid/#overview","title":"Overview","text":"<p>Vehicle ReID matches cars by visual appearance, independent of license plates. This is useful when plates are occluded or unreadable.</p> <p></p>"},{"location":"reid/#how-it-works","title":"How It Works","text":""},{"location":"reid/#1-registration","title":"1. Registration","text":"<pre><code>Upload image/video \u2192 Detect cars \u2192 OCR plates \u2192 Save crops to gallery\n</code></pre> <p>Cars are indexed by their plate ID in <code>data/gallery/{plate_id}/</code>.</p>"},{"location":"reid/#2-search","title":"2. Search","text":"<pre><code>Query video \u2192 Detect cars \u2192 Extract features \u2192 Match with gallery \u2192 Return results\n</code></pre> <p>Each detected car is compared to the gallery using cosine similarity.</p>"},{"location":"reid/#model-architecture","title":"Model Architecture","text":""},{"location":"reid/#resnet50-ibn-backbone","title":"ResNet50-IBN Backbone","text":"<p>Instance-Batch Normalization combines:</p> <ul> <li>Instance Norm: Removes appearance variations (lighting, color)</li> <li>Batch Norm: Preserves discriminative features</li> </ul> <pre><code>class IBN(nn.Module):\n    def __init__(self, planes):\n        self.IN = nn.InstanceNorm2d(planes // 2, affine=True)\n        self.BN = nn.BatchNorm2d(planes // 2)\n\n    def forward(self, x):\n        split = x.chunk(2, 1)\n        out1 = self.IN(split[0])\n        out2 = self.BN(split[1])\n        return torch.cat((out1, out2), 1)\n</code></pre>"},{"location":"reid/#loss-functions","title":"Loss Functions","text":""},{"location":"reid/#contrastive-loss","title":"Contrastive Loss","text":"<p>Pulls similar vehicles together, pushes different vehicles apart:</p> <p>$$L_{contrastive} = \\frac{1}{2N} \\sum_{n=1}^{N} (y_n \\cdot d_n^2 + (1-y_n) \\cdot \\max(0, m - d_n)^2)$$</p> <p>Where:</p> <ul> <li>$d_n$ = Euclidean distance between embeddings</li> <li>$y_n$ = 1 if same vehicle, 0 otherwise</li> <li>$m$ = margin (typically 0.5-1.0)</li> </ul>"},{"location":"reid/#circle-loss","title":"Circle Loss","text":"<p>Provides better convergence with adaptive margins:</p> <p>$$L_{circle} = \\log \\left[ 1 + \\sum_{j} e^{\\gamma \\alpha_j^n (s_j^n - \\Delta_n)} \\cdot \\sum_{k} e^{-\\gamma \\alpha_k^p (s_k^p - \\Delta_p)} \\right]$$</p>"},{"location":"reid/#combined-training","title":"Combined Training","text":"<p>$$L_{total} = L_{ID} + \\lambda_1 L_{contrastive} + \\lambda_2 L_{circle}$$</p>"},{"location":"reid/#usage","title":"Usage","text":""},{"location":"reid/#python-api","title":"Python API","text":"<pre><code>from src.reid.search import (\n    _load_reid_model,\n    _load_gallery_embeddings,\n    _score_candidates,\n    _filter_matches\n)\n\n# Load model\nmodel = _load_reid_model(opts_path, checkpoint_path, device)\n\n# Load gallery\ngallery = _load_gallery_embeddings(\n    gallery_dir, plate_id, model, input_size=224, device=device\n)\n\n# Score candidates\nmatches = _score_candidates(gallery, candidates, model, input_size, device)\n\n# Filter by threshold\nfiltered = _filter_matches(matches, min_score=0.6, top_k=5)\n</code></pre>"},{"location":"reid/#streamlit-app","title":"Streamlit App","text":"<ol> <li>Go to \ud83d\udd0d Vehicle ReID page</li> <li>Register: Upload images/videos to build gallery</li> <li>Search: Select a plate and upload query video</li> <li>Gallery: View all registered vehicles</li> </ol>"},{"location":"reid/#configuration","title":"Configuration","text":"Parameter Default Description <code>input_size</code> 224 ReID input image size <code>batch_size</code> 32 Embedding batch size <code>min_score</code> 0.6 Minimum cosine similarity <code>top_k</code> 5 Max matches per frame"},{"location":"reid/#limitations","title":"Limitations","text":"<ul> <li>Similar Vehicles: Same model/color cars can be confused</li> <li>Lighting: Performance drops in low light</li> <li>Angle: Large viewpoint changes reduce accuracy</li> <li>Occlusion: Partially visible vehicles harder to match</li> </ul>"},{"location":"reid/#references","title":"References","text":"<ul> <li>Paper: Zheng et al., \"Joint Discriminative and Generative Learning for Person Re-identification\", CVPR 2019</li> <li>Code: layumi/Person_reID_baseline_pytorch</li> <li>Tutorial: Kaggle Vehicle ReID</li> </ul>"},{"location":"yolo/","title":"YOLO Detection &amp; OCR","text":"<p>Deep learning-based detection and text recognition for license plates.</p>"},{"location":"yolo/#overview","title":"Overview","text":"<p>The YOLO pipeline uses YOLOv11 for object detection and a custom YOLO OCR model for Arabic character recognition.</p> <p></p>"},{"location":"yolo/#detection-model","title":"Detection Model","text":""},{"location":"yolo/#architecture","title":"Architecture","text":"<p>YOLOv11 consists of three main components:</p> <ul> <li>Backbone: CSPDarknet with C3k2 blocks for feature extraction</li> <li>Neck: PANet (Path Aggregation Network) for multi-scale fusion</li> <li>Head: Detection heads at P3, P4, P5 scales</li> </ul>"},{"location":"yolo/#classes","title":"Classes","text":"Class Description <code>car</code> Vehicle detection <code>plate</code> License plate detection"},{"location":"yolo/#usage","title":"Usage","text":"<pre><code>from ultralytics import YOLO\n\n# Load model\nmodel = YOLO(\"models/best.pt\")\n\n# Detect\nresults = model.predict(image, conf=0.25, iou=0.45)\n\n# Process results\nfor box in results[0].boxes:\n    cls_id = int(box.cls[0])\n    cls_name = model.names[cls_id]\n    x1, y1, x2, y2 = map(int, box.xyxy[0])\n\n    if 'plate' in cls_name.lower():\n        plate_crop = image[y1:y2, x1:x2]\n</code></pre>"},{"location":"yolo/#ocr-model","title":"OCR Model","text":""},{"location":"yolo/#custom-yolo-ocr","title":"Custom YOLO OCR","text":"<p>Instead of traditional OCR, we use a YOLO model trained to detect individual characters:</p> <pre><code>from src.pipeline.yolo_ocr import load_model, read_plate_text\n\n# Load OCR model\nocr_model = load_model(\"models/yolo11m_car_plate_ocr.pt\")\n\n# Read plate\ntext, confidence = read_plate_text(plate_crop, model=ocr_model)\nprint(f\"Plate: {text} ({confidence:.1%})\")\n</code></pre>"},{"location":"yolo/#character-classes","title":"Character Classes","text":"<p>The OCR model detects Arabic letters and numerals:</p> Type Characters Arabic Letters \u0627 \u0628 \u062a \u062b \u062c \u062d \u062e \u062f \u0630 \u0631 \u0632 \u0633 \u0634 \u0635 \u0636 \u0637 \u0638 \u0639 \u063a \u0641 \u0642 \u0643 \u0644 \u0645 \u0646 \u0647 \u0648 \u064a Numerals 0 1 2 3 4 5 6 7 8 9"},{"location":"yolo/#character-assembly","title":"Character Assembly","text":"<p>Characters are sorted left-to-right and assembled into the plate text:</p> <pre><code>def read_plate_text(plate_crop, model, conf=0.25):\n    results = model.predict(plate_crop, conf=conf, verbose=False)\n\n    detections = []\n    for box in results[0].boxes:\n        cls_id = int(box.cls[0])\n        x_center = (box.xyxy[0][0] + box.xyxy[0][2]) / 2\n        char = model.names[cls_id]\n        detections.append((x_center, char))\n\n    # Sort by x position (left to right)\n    detections.sort(key=lambda x: x[0])\n\n    # Assemble text\n    text = ''.join([d[1] for d in detections])\n    return text\n</code></pre>"},{"location":"yolo/#configuration","title":"Configuration","text":""},{"location":"yolo/#detection-parameters","title":"Detection Parameters","text":"Parameter Default Description <code>conf</code> 0.25 Confidence threshold <code>iou</code> 0.45 NMS IoU threshold <code>device</code> auto GPU/CPU selection"},{"location":"yolo/#model-files","title":"Model Files","text":"<pre><code>models/\n\u251c\u2500\u2500 best.pt                    # Detection model\n\u2514\u2500\u2500 yolo11m_car_plate_ocr.pt   # OCR model\n</code></pre>"},{"location":"yolo/#training","title":"Training","text":"<p>Models were trained on Ultralytics HUB:</p> <ul> <li>Detection: Custom Egyptian plate dataset</li> <li>OCR: Character-level annotations on plate crops</li> </ul> <p>See Training Dashboard for metrics.</p>"},{"location":"yolo/#comparison-with-easyocr","title":"Comparison with EasyOCR","text":"Feature YOLO OCR EasyOCR Speed Faster Slower Arabic Support Trained General Accuracy Higher for Egyptian Lower for Arabic Dependencies Ultralytics easyocr, torch"}]}